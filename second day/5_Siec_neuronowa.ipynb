{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
      " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
      " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
      " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
      " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.loadtxt('ex5.csv', delimiter=',')\n",
    "print(dataset)\n",
    "#podział na dane i etykiety, 1 - cukrzyk, 0 - zdrowy\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmienne wejściowe:\n",
    "Liczba ciąż\n",
    "Stężenie glukozy w osoczu po 2 godzinach w doustnym teście tolerancji glukozy\n",
    "Rozkurczowe ciśnienie krwi (mm Hg)\n",
    "Grubość fałdu skórnego tricepsa (mm)\n",
    "2-godzinne stężenie insuliny w surowicy (μIU/ml)\n",
    "Wskaźnik masy ciała (waga w kg/(wzrost w m)2)\n",
    "Funkcja rodowodu cukrzycy\n",
    "Wiek (lata)\n",
    "\n",
    "Y: Etykieta klasy (0 lub 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smonn\\AppData\\Local\\Temp\\ipykernel_4852\\1146932885.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n",
      "C:\\Users\\smonn\\AppData\\Local\\Temp\\ipykernel_4852\\1146932885.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = nn.Sequential(  #seq - chcemy sieć warstową\n",
    "    nn.Linear(8, 12),   #model liniowy, zaczynamy od 8 neuronów, przesyłamy do warstwy z dwunastoma\n",
    "    nn.ReLU(),          #funkcja aktywacyjna (nieiniowa)\n",
    "    nn.Linear(12, 8),   #kolejna warstwa liniowa, z 12 do 8, 12 ważne, 8 obojetne\n",
    "    nn.ReLU(),          #kolejna fun aktyw\n",
    "    nn.Linear(8, 1),    #konczymy warstwy, na końcu jedna cecha, czyli dane zostaną sklasyfikowane binarnie (chory lub nie)\n",
    "    nn.Sigmoid())       #funkcja sigmoidalna, prawdopodobiensto przy binarce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (hidden1): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importuj bibliotekę PyTorch.\n",
    "import torch.nn as nn\n",
    "\n",
    "# Definiuj klasę Classifier, która dziedziczy po nn.Module z PyTorch.\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Definiuj warstwy sieci neuronowej.\n",
    "        self.hidden1 = nn.Linear(8, 12)  # Warstwa ukryta 1 z 8 wejściami i 12 wyjściami.\n",
    "        self.act1 = nn.ReLU()  # Funkcja aktywacji ReLU po warstwie ukrytej 1.\n",
    "        self.hidden2 = nn.Linear(12, 8)  # Warstwa ukryta 2 z 12 wejściami i 8 wyjściami.\n",
    "        self.act2 = nn.ReLU()  # Funkcja aktywacji ReLU po warstwie ukrytej 2.\n",
    "        self.output = nn.Linear(8, 1)  # Warstwa wyjściowa z 8 wejściami i 1 wyjściem.\n",
    "        self.act_output = nn.Sigmoid()  # Funkcja aktywacji Sigmoid po warstwie wyjściowej.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Określa przód (forward pass) sieci neuronowej.\n",
    "        x = self.act1(self.hidden1(x))  # Przeprowadza dane przez warstwę ukrytą 1 z ReLU.\n",
    "        x = self.act2(self.hidden2(x))  # Przeprowadza dane przez warstwę ukrytą 2 z ReLU.\n",
    "        x = self.act_output(self.output(x))  # Przeprowadza dane przez warstwę wyjściową z Sigmoid.\n",
    "        return x\n",
    "\n",
    "# Tworzy instancję modelu klasyfikatora.\n",
    "model = Classifier()\n",
    "\n",
    "# Wyświetla definicję modelu.\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja straty i optymalizacyjna\n",
    "loss_fn = nn.BCELoss() #binary cros entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #learning rate - mniejsza, wolniej ale dokładniej, wieksza, szybciej ale mniej dokładnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0, funkcja straty 0.5018962025642395\n",
      "Epoka 1, funkcja straty 0.46620500087738037\n",
      "Epoka 2, funkcja straty 0.44237205386161804\n",
      "Epoka 3, funkcja straty 0.43939581513404846\n",
      "Epoka 4, funkcja straty 0.4387891888618469\n",
      "Epoka 5, funkcja straty 0.4418601095676422\n",
      "Epoka 6, funkcja straty 0.4399087429046631\n",
      "Epoka 7, funkcja straty 0.44107887148857117\n",
      "Epoka 8, funkcja straty 0.44126611948013306\n",
      "Epoka 9, funkcja straty 0.44267991185188293\n",
      "Epoka 10, funkcja straty 0.44478562474250793\n",
      "Epoka 11, funkcja straty 0.44560256600379944\n",
      "Epoka 12, funkcja straty 0.4494945704936981\n",
      "Epoka 13, funkcja straty 0.4513058364391327\n",
      "Epoka 14, funkcja straty 0.44997867941856384\n",
      "Epoka 15, funkcja straty 0.4501210153102875\n",
      "Epoka 16, funkcja straty 0.4494994878768921\n",
      "Epoka 17, funkcja straty 0.45332005620002747\n",
      "Epoka 18, funkcja straty 0.45423561334609985\n",
      "Epoka 19, funkcja straty 0.45327669382095337\n",
      "Epoka 20, funkcja straty 0.4548243284225464\n",
      "Epoka 21, funkcja straty 0.4525006413459778\n",
      "Epoka 22, funkcja straty 0.4412444829940796\n",
      "Epoka 23, funkcja straty 0.4355967938899994\n",
      "Epoka 24, funkcja straty 0.434099018573761\n",
      "Epoka 25, funkcja straty 0.42689448595046997\n",
      "Epoka 26, funkcja straty 0.42061421275138855\n",
      "Epoka 27, funkcja straty 0.41915953159332275\n",
      "Epoka 28, funkcja straty 0.41863304376602173\n",
      "Epoka 29, funkcja straty 0.4143158793449402\n",
      "Epoka 30, funkcja straty 0.42596516013145447\n",
      "Epoka 31, funkcja straty 0.42252302169799805\n",
      "Epoka 32, funkcja straty 0.40899163484573364\n",
      "Epoka 33, funkcja straty 0.4032701849937439\n",
      "Epoka 34, funkcja straty 0.41735631227493286\n",
      "Epoka 35, funkcja straty 0.4006079435348511\n",
      "Epoka 36, funkcja straty 0.4082295298576355\n",
      "Epoka 37, funkcja straty 0.4064953327178955\n",
      "Epoka 38, funkcja straty 0.40148478746414185\n",
      "Epoka 39, funkcja straty 0.4008494019508362\n",
      "Epoka 40, funkcja straty 0.4039129614830017\n",
      "Epoka 41, funkcja straty 0.40519237518310547\n",
      "Epoka 42, funkcja straty 0.39955660700798035\n",
      "Epoka 43, funkcja straty 0.3692542612552643\n",
      "Epoka 44, funkcja straty 0.3949536681175232\n",
      "Epoka 45, funkcja straty 0.38507434725761414\n",
      "Epoka 46, funkcja straty 0.3949173092842102\n",
      "Epoka 47, funkcja straty 0.3907672166824341\n",
      "Epoka 48, funkcja straty 0.37921178340911865\n",
      "Epoka 49, funkcja straty 0.36195099353790283\n",
      "Epoka 50, funkcja straty 0.35532400012016296\n",
      "Epoka 51, funkcja straty 0.37119513750076294\n",
      "Epoka 52, funkcja straty 0.3662968873977661\n",
      "Epoka 53, funkcja straty 0.3629785180091858\n",
      "Epoka 54, funkcja straty 0.36100372672080994\n",
      "Epoka 55, funkcja straty 0.36203068494796753\n",
      "Epoka 56, funkcja straty 0.3632153272628784\n",
      "Epoka 57, funkcja straty 0.3614543080329895\n",
      "Epoka 58, funkcja straty 0.37464526295661926\n",
      "Epoka 59, funkcja straty 0.37279582023620605\n",
      "Epoka 60, funkcja straty 0.3695852756500244\n",
      "Epoka 61, funkcja straty 0.3726789057254791\n",
      "Epoka 62, funkcja straty 0.3560450077056885\n",
      "Epoka 63, funkcja straty 0.36911752820014954\n",
      "Epoka 64, funkcja straty 0.36563920974731445\n",
      "Epoka 65, funkcja straty 0.36739805340766907\n",
      "Epoka 66, funkcja straty 0.3591991662979126\n",
      "Epoka 67, funkcja straty 0.36750441789627075\n",
      "Epoka 68, funkcja straty 0.37173011898994446\n",
      "Epoka 69, funkcja straty 0.36421725153923035\n",
      "Epoka 70, funkcja straty 0.36969494819641113\n",
      "Epoka 71, funkcja straty 0.353028267621994\n",
      "Epoka 72, funkcja straty 0.3653653860092163\n",
      "Epoka 73, funkcja straty 0.3612000048160553\n",
      "Epoka 74, funkcja straty 0.36330264806747437\n",
      "Epoka 75, funkcja straty 0.3501792848110199\n",
      "Epoka 76, funkcja straty 0.3387957513332367\n",
      "Epoka 77, funkcja straty 0.3507416844367981\n",
      "Epoka 78, funkcja straty 0.3640843331813812\n",
      "Epoka 79, funkcja straty 0.36101800203323364\n",
      "Epoka 80, funkcja straty 0.34556394815444946\n",
      "Epoka 81, funkcja straty 0.3675585389137268\n",
      "Epoka 82, funkcja straty 0.36678099632263184\n",
      "Epoka 83, funkcja straty 0.36712250113487244\n",
      "Epoka 84, funkcja straty 0.36985865235328674\n",
      "Epoka 85, funkcja straty 0.36050286889076233\n",
      "Epoka 86, funkcja straty 0.3430139422416687\n",
      "Epoka 87, funkcja straty 0.35716381669044495\n",
      "Epoka 88, funkcja straty 0.34019115567207336\n",
      "Epoka 89, funkcja straty 0.3386751711368561\n",
      "Epoka 90, funkcja straty 0.35915568470954895\n",
      "Epoka 91, funkcja straty 0.33848363161087036\n",
      "Epoka 92, funkcja straty 0.3332591652870178\n",
      "Epoka 93, funkcja straty 0.33778253197669983\n",
      "Epoka 94, funkcja straty 0.3560572862625122\n",
      "Epoka 95, funkcja straty 0.3505132496356964\n",
      "Epoka 96, funkcja straty 0.34840017557144165\n",
      "Epoka 97, funkcja straty 0.34645089507102966\n",
      "Epoka 98, funkcja straty 0.34208858013153076\n",
      "Epoka 99, funkcja straty 0.3392230272293091\n"
     ]
    }
   ],
   "source": [
    "# Liczba epok i rozmiar partii (batch size) w treningu.\n",
    "n_epochs = 100 #epoka - jedno przejscie przez sieć\n",
    "batch_size = 10 # do sieci nie wrzuca się wszystkich danych naraz tylko w paczkach (batchach)\n",
    "\n",
    "# Pętla treningowa po epokach.\n",
    "for epoch in range(n_epochs):\n",
    "    # Pętla treningowa po danych treningowych z podziałem na partie (mini-batch).\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        # weź jedną paczkę (0:10, 10:20 ...)\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        \n",
    "        # Przewiduje wyniki za pomocą modelu.\n",
    "        y_pred = model(Xbatch)\n",
    "        \n",
    "        # weź realne wyniki \n",
    "        ybatch = y[i:i+batch_size]\n",
    "        \n",
    "        # porownaj realne z predictem i wylicz stratę\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        \n",
    "        # Wyzerowuje gradienty w optymalizatorze.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Oblicza gradienty straty wstecz (backpropagation).\n",
    "        loss.backward()\n",
    "        \n",
    "        # Aktualizuje wagi modelu na podstawie gradientów.\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Wyświetla informacje o postępie treningu po każdej epoce.\n",
    "    print(f'Epoka {epoch}, funkcja straty {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.weight tensor([[ 0.2718, -0.4622, -0.1692, -0.1580,  0.1640, -0.4429,  1.7011, -0.0578],\n",
      "        [ 0.0510, -0.2825, -0.1407, -0.0464,  0.1094, -0.4303,  0.2121, -0.4410],\n",
      "        [ 0.2520, -0.1854,  0.4417, -0.3992,  0.1222, -0.2979, -0.7479, -0.5387],\n",
      "        [ 0.2869, -0.1861, -0.2996,  0.1911, -0.3443, -0.1503, -0.0666,  0.2818],\n",
      "        [-0.0172,  0.0348, -0.0942, -0.0036,  0.0813, -0.1273,  1.6777,  0.3294],\n",
      "        [ 0.4122,  0.1305, -0.0090,  0.0317, -0.0507,  0.5481,  2.1698, -0.3042],\n",
      "        [-0.7797, -0.1355,  0.4164, -0.2943,  0.0395, -0.1347, -1.1388, -0.0133],\n",
      "        [ 0.5729, -0.1215, -0.2210, -0.3744,  0.0349, -0.1083,  0.1360,  0.6263],\n",
      "        [ 0.0100, -0.3553, -0.0114, -0.0903,  0.0476,  0.1359, -0.3738, -0.1280],\n",
      "        [ 1.0385, -0.3766, -0.2266, -0.2859,  0.0956,  0.2707,  0.3278,  0.4301],\n",
      "        [ 0.6106,  0.0862, -0.1832, -0.0100, -0.2423,  0.1580,  0.9822,  0.1066],\n",
      "        [-0.2701, -0.0513,  0.0571, -0.3585,  0.0897,  0.1382, -1.7941, -0.2182]])\n",
      "hidden1.bias tensor([-0.6773, -0.0295,  0.3968, -0.0746, -2.4050, -1.6737,  1.5457,  0.7237,\n",
      "         0.0298, -0.6604, -1.8650,  1.2256])\n",
      "hidden2.weight tensor([[ 0.2560,  0.2532, -0.0427,  0.2404, -0.1520, -0.0825, -0.2094,  0.1195,\n",
      "         -0.2034, -0.2037, -0.2613, -0.1965],\n",
      "        [-0.1943,  0.0367, -0.0399,  0.0888,  0.1157, -0.4173,  0.3687,  0.1640,\n",
      "         -0.2317,  1.2385,  0.2614,  0.2654],\n",
      "        [-0.1785, -0.1853, -0.0262,  0.1035, -0.2885, -0.1998, -0.1361, -0.1319,\n",
      "         -0.2260,  0.0683,  0.0916,  0.1121],\n",
      "        [-0.9133,  0.0793,  0.1153,  0.1553,  0.0908,  0.4258, -0.2008, -0.0624,\n",
      "          0.1178,  1.5785, -0.0364, -0.0116],\n",
      "        [-0.0212,  0.0121, -0.0236,  0.0603, -0.1498, -0.3274, -0.2762,  0.1697,\n",
      "         -0.0275,  0.1635, -0.2069,  0.1630],\n",
      "        [-0.1446,  0.1097, -0.2661, -0.0444, -0.0603,  0.0414,  0.0602,  0.4209,\n",
      "         -0.1215, -0.8492,  0.1439,  0.1835],\n",
      "        [ 0.2857,  0.0200,  0.2605,  0.2593, -0.2300,  0.0688,  0.0124,  0.4605,\n",
      "         -0.0654, -0.7641, -0.3387,  0.2078],\n",
      "        [-0.0672, -0.3178, -0.7072,  0.1062,  0.0788,  0.0816,  0.3583,  0.0885,\n",
      "         -0.0876,  1.4004,  0.1548,  0.0701]])\n",
      "hidden2.bias tensor([-0.0716, -0.5180,  0.1574, -2.0177, -0.0198,  2.3070,  2.7284, -2.1577])\n",
      "output.weight tensor([[-0.0193,  0.4192, -0.0228,  0.4900, -0.2616, -0.4756, -0.7791,  0.4779]])\n",
      "output.bias tensor([-2.1869])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name,param.data)\n",
    "#wyswietlenie wag i biasow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wagi warstwy hidden2: tensor([[     0.0074,     -0.9490,      0.0966,     -0.3355,      0.2612,\n",
      "              0.3390,     -0.0450,      0.0885,     -0.0542,      0.0355,\n",
      "             -0.0825,     -0.0497],\n",
      "        [     0.2087,     -0.2475,      0.1929,      0.1481,      0.0947,\n",
      "              0.1585,     -0.2805,      0.2898,      0.0161,      0.0831,\n",
      "             -0.0191,      0.0073],\n",
      "        [    -0.0063,      0.3095,     -0.1941,      0.0660,     -0.4196,\n",
      "              0.1925,      0.0640,      0.2057,     -0.3462,      0.5891,\n",
      "             -0.2409,      0.2446],\n",
      "        [     0.0180,     -0.0050,      0.1705,     -0.0340,      0.2193,\n",
      "             -0.0490,      0.1842,      0.0012,     -0.0993,      0.1922,\n",
      "              0.0135,      0.1446],\n",
      "        [    -0.0101,     -0.1425,      0.0835,     -0.0299,     -0.0624,\n",
      "             -0.1836,      0.1978,     -0.2493,      0.1236,     -0.1589,\n",
      "             -0.1331,     -0.0497],\n",
      "        [    -0.1729,     -0.0322,     -0.1492,      0.0753,     -0.2568,\n",
      "             -0.4963,     -0.1302,     -0.1864,      0.1859,     -0.2769,\n",
      "              0.0309,      0.0440],\n",
      "        [     0.1525,     -0.0780,      0.2187,     -0.0401,     -0.1103,\n",
      "             -0.2254,      0.1810,      0.1310,     -0.0026,     -0.1911,\n",
      "             -0.0735,     -0.0913],\n",
      "        [    -0.0004,      0.0465,      0.2934,      0.0392,      0.1582,\n",
      "             -0.1351,      0.0368,      0.0346,      0.0713,     -0.0419,\n",
      "              0.0683,      0.0957]])\n",
      "Biasy warstwy hidden2: tensor([-0.7710,  1.0434,  0.1603,  0.9912,  1.2406,  0.2607,  1.3901, -1.3124])\n"
     ]
    }
   ],
   "source": [
    "wagi_hidden2 = model.hidden2.weight.data\n",
    "biasy_hidden2 = model.hidden2.bias.data\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print('Wagi warstwy hidden2:', wagi_hidden2)\n",
    "print('Biasy warstwy hidden2:', biasy_hidden2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8190)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ustaw tryb ewaluacji (bez obliczania gradientów) za pomocą torch.no_grad().\n",
    "with torch.no_grad():\n",
    "    # Przewiduje wyniki za pomocą modelu na całym zbiorze danych treningowych.\n",
    "    y_pred = model(X)\n",
    "(y_pred.round() == y).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7981770634651184\n"
     ]
    }
   ],
   "source": [
    "# Oblicza dokładność (accuracy) modelu na danych treningowych.\n",
    "# Dokładność to procent poprawnie sklasyfikowanych przykładów.\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "\n",
    "# Wyświetla wynik dokładności.\n",
    "print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=24, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=24, out_features=8, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (7): Sigmoid()\n",
      ")\n",
      "Epoka 0, funkcja straty 0.6401198506355286\n",
      "Epoka 1, funkcja straty 0.5858009457588196\n",
      "Epoka 2, funkcja straty 0.5429348349571228\n",
      "Epoka 3, funkcja straty 0.506710410118103\n",
      "Epoka 4, funkcja straty 0.47376570105552673\n",
      "Epoka 5, funkcja straty 0.4528835117816925\n",
      "Epoka 6, funkcja straty 0.43767133355140686\n",
      "Epoka 7, funkcja straty 0.42387625575065613\n",
      "Epoka 8, funkcja straty 0.40815070271492004\n",
      "Epoka 9, funkcja straty 0.412801057100296\n",
      "Epoka 10, funkcja straty 0.4040161371231079\n",
      "Epoka 11, funkcja straty 0.4033040702342987\n",
      "Epoka 12, funkcja straty 0.39069345593452454\n",
      "Epoka 13, funkcja straty 0.37809574604034424\n",
      "Epoka 14, funkcja straty 0.37628915905952454\n",
      "Epoka 15, funkcja straty 0.37351348996162415\n",
      "Epoka 16, funkcja straty 0.3490004539489746\n",
      "Epoka 17, funkcja straty 0.3538565933704376\n",
      "Epoka 18, funkcja straty 0.3570002615451813\n",
      "Epoka 19, funkcja straty 0.34022247791290283\n",
      "Epoka 20, funkcja straty 0.32355546951293945\n",
      "Epoka 21, funkcja straty 0.32424238324165344\n",
      "Epoka 22, funkcja straty 0.3126899003982544\n",
      "Epoka 23, funkcja straty 0.3063238561153412\n",
      "Epoka 24, funkcja straty 0.31086480617523193\n",
      "Epoka 25, funkcja straty 0.3044126331806183\n",
      "Epoka 26, funkcja straty 0.3015056848526001\n",
      "Epoka 27, funkcja straty 0.299470454454422\n",
      "Epoka 28, funkcja straty 0.2995831072330475\n",
      "Epoka 29, funkcja straty 0.2768332064151764\n",
      "Epoka 30, funkcja straty 0.26504984498023987\n",
      "Epoka 31, funkcja straty 0.26791703701019287\n",
      "Epoka 32, funkcja straty 0.27226099371910095\n",
      "Epoka 33, funkcja straty 0.25901880860328674\n",
      "Epoka 34, funkcja straty 0.2551465332508087\n",
      "Epoka 35, funkcja straty 0.25883999466896057\n",
      "Epoka 36, funkcja straty 0.2571120262145996\n",
      "Epoka 37, funkcja straty 0.2576552927494049\n",
      "Epoka 38, funkcja straty 0.25260108709335327\n",
      "Epoka 39, funkcja straty 0.25141990184783936\n",
      "Epoka 40, funkcja straty 0.25347962975502014\n",
      "Epoka 41, funkcja straty 0.25455352663993835\n",
      "Epoka 42, funkcja straty 0.2509823739528656\n",
      "Epoka 43, funkcja straty 0.25007346272468567\n",
      "Epoka 44, funkcja straty 0.252526193857193\n",
      "Epoka 45, funkcja straty 0.2510647475719452\n",
      "Epoka 46, funkcja straty 0.247624471783638\n",
      "Epoka 47, funkcja straty 0.24767768383026123\n",
      "Epoka 48, funkcja straty 0.2489500641822815\n",
      "Epoka 49, funkcja straty 0.24453477561473846\n",
      "Epoka 50, funkcja straty 0.24521100521087646\n",
      "Epoka 51, funkcja straty 0.24217276275157928\n",
      "Epoka 52, funkcja straty 0.24535579979419708\n",
      "Epoka 53, funkcja straty 0.24148036539554596\n",
      "Epoka 54, funkcja straty 0.23994821310043335\n",
      "Epoka 55, funkcja straty 0.24108044803142548\n",
      "Epoka 56, funkcja straty 0.23721586167812347\n",
      "Epoka 57, funkcja straty 0.23538535833358765\n",
      "Epoka 58, funkcja straty 0.23623399436473846\n",
      "Epoka 59, funkcja straty 0.23836453258991241\n",
      "Epoka 60, funkcja straty 0.2344425916671753\n",
      "Epoka 61, funkcja straty 0.23442614078521729\n",
      "Epoka 62, funkcja straty 0.23423652350902557\n",
      "Epoka 63, funkcja straty 0.23472432792186737\n",
      "Epoka 64, funkcja straty 0.23417413234710693\n",
      "Epoka 65, funkcja straty 0.23050348460674286\n",
      "Epoka 66, funkcja straty 0.2347262054681778\n",
      "Epoka 67, funkcja straty 0.23162619769573212\n",
      "Epoka 68, funkcja straty 0.2304455041885376\n",
      "Epoka 69, funkcja straty 0.22485870122909546\n",
      "Epoka 70, funkcja straty 0.2239106446504593\n",
      "Epoka 71, funkcja straty 0.22852039337158203\n",
      "Epoka 72, funkcja straty 0.22774942219257355\n",
      "Epoka 73, funkcja straty 0.22462628781795502\n",
      "Epoka 74, funkcja straty 0.23098574578762054\n",
      "Epoka 75, funkcja straty 0.2270612269639969\n",
      "Epoka 76, funkcja straty 0.22688078880310059\n",
      "Epoka 77, funkcja straty 0.22912096977233887\n",
      "Epoka 78, funkcja straty 0.2220517247915268\n",
      "Epoka 79, funkcja straty 0.22481685876846313\n",
      "Epoka 80, funkcja straty 0.2235383838415146\n",
      "Epoka 81, funkcja straty 0.22595016658306122\n",
      "Epoka 82, funkcja straty 0.2262629270553589\n",
      "Epoka 83, funkcja straty 0.23087990283966064\n",
      "Epoka 84, funkcja straty 0.22010664641857147\n",
      "Epoka 85, funkcja straty 0.22524140775203705\n",
      "Epoka 86, funkcja straty 0.21994148194789886\n",
      "Epoka 87, funkcja straty 0.21756987273693085\n",
      "Epoka 88, funkcja straty 0.22207339107990265\n",
      "Epoka 89, funkcja straty 0.22396327555179596\n",
      "Epoka 90, funkcja straty 0.22330982983112335\n",
      "Epoka 91, funkcja straty 0.228580042719841\n",
      "Epoka 92, funkcja straty 0.22832708060741425\n",
      "Epoka 93, funkcja straty 0.2245514988899231\n",
      "Epoka 94, funkcja straty 0.2228803038597107\n",
      "Epoka 95, funkcja straty 0.2203141301870346\n",
      "Epoka 96, funkcja straty 0.2233460545539856\n",
      "Epoka 97, funkcja straty 0.2202148586511612\n",
      "Epoka 98, funkcja straty 0.22648245096206665\n",
      "Epoka 99, funkcja straty 0.2200586348772049\n",
      "Epoka 100, funkcja straty 0.21938246488571167\n",
      "Epoka 101, funkcja straty 0.21828359365463257\n",
      "Epoka 102, funkcja straty 0.21324522793293\n",
      "Epoka 103, funkcja straty 0.21489255130290985\n",
      "Epoka 104, funkcja straty 0.21957017481327057\n",
      "Epoka 105, funkcja straty 0.21769440174102783\n",
      "Epoka 106, funkcja straty 0.21658867597579956\n",
      "Epoka 107, funkcja straty 0.2160906344652176\n",
      "Epoka 108, funkcja straty 0.21890898048877716\n",
      "Epoka 109, funkcja straty 0.21733231842517853\n",
      "Epoka 110, funkcja straty 0.21424667537212372\n",
      "Epoka 111, funkcja straty 0.2150554656982422\n",
      "Epoka 112, funkcja straty 0.2213456779718399\n",
      "Epoka 113, funkcja straty 0.21482549607753754\n",
      "Epoka 114, funkcja straty 0.21378006041049957\n",
      "Epoka 115, funkcja straty 0.22050213813781738\n",
      "Epoka 116, funkcja straty 0.21175317466259003\n",
      "Epoka 117, funkcja straty 0.21129800379276276\n",
      "Epoka 118, funkcja straty 0.21392248570919037\n",
      "Epoka 119, funkcja straty 0.2150326818227768\n",
      "Epoka 120, funkcja straty 0.20560412108898163\n",
      "Epoka 121, funkcja straty 0.2132810801267624\n",
      "Epoka 122, funkcja straty 0.21233993768692017\n",
      "Epoka 123, funkcja straty 0.21231019496917725\n",
      "Epoka 124, funkcja straty 0.21235771477222443\n",
      "Epoka 125, funkcja straty 0.2009875327348709\n",
      "Epoka 126, funkcja straty 0.20083747804164886\n",
      "Epoka 127, funkcja straty 0.2044845074415207\n",
      "Epoka 128, funkcja straty 0.20533187687397003\n",
      "Epoka 129, funkcja straty 0.19908583164215088\n",
      "Epoka 130, funkcja straty 0.20076334476470947\n",
      "Epoka 131, funkcja straty 0.19570398330688477\n",
      "Epoka 132, funkcja straty 0.19555418193340302\n",
      "Epoka 133, funkcja straty 0.19021503627300262\n",
      "Epoka 134, funkcja straty 0.19435448944568634\n",
      "Epoka 135, funkcja straty 0.19111327826976776\n",
      "Epoka 136, funkcja straty 0.19120573997497559\n",
      "Epoka 137, funkcja straty 0.19306619465351105\n",
      "Epoka 138, funkcja straty 0.18594390153884888\n",
      "Epoka 139, funkcja straty 0.19499506056308746\n",
      "Epoka 140, funkcja straty 0.19093556702136993\n",
      "Epoka 141, funkcja straty 0.1867402344942093\n",
      "Epoka 142, funkcja straty 0.19225634634494781\n",
      "Epoka 143, funkcja straty 0.1886683702468872\n",
      "Epoka 144, funkcja straty 0.19039006531238556\n",
      "Epoka 145, funkcja straty 0.1854873150587082\n",
      "Epoka 146, funkcja straty 0.18444328010082245\n",
      "Epoka 147, funkcja straty 0.1895054429769516\n",
      "Epoka 148, funkcja straty 0.18996238708496094\n",
      "Epoka 149, funkcja straty 0.18737636506557465\n",
      "Epoka 150, funkcja straty 0.1945432424545288\n",
      "Epoka 151, funkcja straty 0.1935032606124878\n",
      "Epoka 152, funkcja straty 0.18885241448879242\n",
      "Epoka 153, funkcja straty 0.1894092559814453\n",
      "Epoka 154, funkcja straty 0.18813131749629974\n",
      "Epoka 155, funkcja straty 0.19734220206737518\n",
      "Epoka 156, funkcja straty 0.19402040541172028\n",
      "Epoka 157, funkcja straty 0.19664812088012695\n",
      "Epoka 158, funkcja straty 0.1904485821723938\n",
      "Epoka 159, funkcja straty 0.1980832815170288\n",
      "Epoka 160, funkcja straty 0.19043469429016113\n",
      "Epoka 161, funkcja straty 0.19589011371135712\n",
      "Epoka 162, funkcja straty 0.20007319748401642\n",
      "Epoka 163, funkcja straty 0.19348883628845215\n",
      "Epoka 164, funkcja straty 0.19881312549114227\n",
      "Epoka 165, funkcja straty 0.19312679767608643\n",
      "Epoka 166, funkcja straty 0.1902226358652115\n",
      "Epoka 167, funkcja straty 0.19293437898159027\n",
      "Epoka 168, funkcja straty 0.19893646240234375\n",
      "Epoka 169, funkcja straty 0.19935180246829987\n",
      "Epoka 170, funkcja straty 0.1889144629240036\n",
      "Epoka 171, funkcja straty 0.19303704798221588\n",
      "Epoka 172, funkcja straty 0.19776810705661774\n",
      "Epoka 173, funkcja straty 0.19062460958957672\n",
      "Epoka 174, funkcja straty 0.1983134150505066\n",
      "Epoka 175, funkcja straty 0.20562313497066498\n",
      "Epoka 176, funkcja straty 0.19700448215007782\n",
      "Epoka 177, funkcja straty 0.2003084421157837\n",
      "Epoka 178, funkcja straty 0.20083196461200714\n",
      "Epoka 179, funkcja straty 0.19818739593029022\n",
      "Epoka 180, funkcja straty 0.19975675642490387\n",
      "Epoka 181, funkcja straty 0.19372715055942535\n",
      "Epoka 182, funkcja straty 0.19161038100719452\n",
      "Epoka 183, funkcja straty 0.2067345231771469\n",
      "Epoka 184, funkcja straty 0.20144706964492798\n",
      "Epoka 185, funkcja straty 0.20420701801776886\n",
      "Epoka 186, funkcja straty 0.20172016322612762\n",
      "Epoka 187, funkcja straty 0.20385394990444183\n",
      "Epoka 188, funkcja straty 0.19813235104084015\n",
      "Epoka 189, funkcja straty 0.20214404165744781\n",
      "Epoka 190, funkcja straty 0.21219265460968018\n",
      "Epoka 191, funkcja straty 0.2000299096107483\n",
      "Epoka 192, funkcja straty 0.20919227600097656\n",
      "Epoka 193, funkcja straty 0.19477230310440063\n",
      "Epoka 194, funkcja straty 0.21354813873767853\n",
      "Epoka 195, funkcja straty 0.2091531753540039\n",
      "Epoka 196, funkcja straty 0.19779177010059357\n",
      "Epoka 197, funkcja straty 0.1979076862335205\n",
      "Epoka 198, funkcja straty 0.19944888353347778\n",
      "Epoka 199, funkcja straty 0.18950754404067993\n",
      "Accuracy 0.8255208134651184\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "dataset = np.loadtxt('ex5.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12,24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24,8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "print(model)\n",
    "\n",
    "\n",
    "loss_fn   = nn.BCELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 200\n",
    "batch_size = 15\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoka {epoch}, funkcja straty {loss}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model(X)\n",
    "\n",
    "rounded = predictions.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = (model(X) > 0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 78.0, 50.0, 32.0, 88.0, 31.0, 0.24799999594688416, 26.0] => 0 (oczekiwane 1)\n",
      "[10.0, 115.0, 0.0, 0.0, 0.0, 35.29999923706055, 0.1340000033378601, 29.0] => 1 (oczekiwane 0)\n",
      "[8.0, 125.0, 96.0, 0.0, 0.0, 0.0, 0.23199999332427979, 54.0] => 0 (oczekiwane 1)\n",
      "[7.0, 100.0, 0.0, 0.0, 0.0, 30.0, 0.48399999737739563, 32.0] => 0 (oczekiwane 1)\n",
      "[0.0, 118.0, 84.0, 47.0, 230.0, 45.79999923706055, 0.5509999990463257, 31.0] => 0 (oczekiwane 1)\n",
      "[7.0, 107.0, 74.0, 0.0, 0.0, 29.600000381469727, 0.2540000081062317, 31.0] => 0 (oczekiwane 1)\n",
      "[1.0, 115.0, 70.0, 30.0, 96.0, 34.599998474121094, 0.5289999842643738, 32.0] => 0 (oczekiwane 1)\n",
      "[9.0, 119.0, 80.0, 35.0, 0.0, 29.0, 0.2630000114440918, 29.0] => 0 (oczekiwane 1)\n",
      "[11.0, 143.0, 94.0, 33.0, 146.0, 36.599998474121094, 0.2540000081062317, 51.0] => 0 (oczekiwane 1)\n",
      "[10.0, 125.0, 70.0, 26.0, 115.0, 31.100000381469727, 0.20499999821186066, 41.0] => 0 (oczekiwane 1)\n",
      "[10.0, 122.0, 78.0, 31.0, 0.0, 27.600000381469727, 0.5120000243186951, 45.0] => 1 (oczekiwane 0)\n",
      "[11.0, 138.0, 76.0, 0.0, 0.0, 33.20000076293945, 0.41999998688697815, 35.0] => 1 (oczekiwane 0)\n",
      "[9.0, 102.0, 76.0, 37.0, 0.0, 32.900001525878906, 0.6650000214576721, 46.0] => 0 (oczekiwane 1)\n",
      "[2.0, 90.0, 68.0, 42.0, 0.0, 38.20000076293945, 0.503000020980835, 27.0] => 0 (oczekiwane 1)\n",
      "[7.0, 133.0, 84.0, 0.0, 0.0, 40.20000076293945, 0.6959999799728394, 37.0] => 1 (oczekiwane 0)\n",
      "[7.0, 159.0, 64.0, 0.0, 0.0, 27.399999618530273, 0.2939999997615814, 40.0] => 1 (oczekiwane 0)\n",
      "[1.0, 146.0, 56.0, 0.0, 0.0, 29.700000762939453, 0.5640000104904175, 29.0] => 1 (oczekiwane 0)\n",
      "[7.0, 103.0, 66.0, 32.0, 0.0, 39.099998474121094, 0.3440000116825104, 31.0] => 0 (oczekiwane 1)\n",
      "[7.0, 150.0, 66.0, 42.0, 342.0, 34.70000076293945, 0.7179999947547913, 42.0] => 1 (oczekiwane 0)\n",
      "[0.0, 146.0, 82.0, 0.0, 0.0, 40.5, 1.781000018119812, 44.0] => 1 (oczekiwane 0)\n",
      "[7.0, 114.0, 66.0, 0.0, 0.0, 32.79999923706055, 0.257999986410141, 42.0] => 0 (oczekiwane 1)\n",
      "[0.0, 109.0, 88.0, 30.0, 0.0, 32.5, 0.8550000190734863, 38.0] => 0 (oczekiwane 1)\n",
      "[2.0, 100.0, 66.0, 20.0, 90.0, 32.900001525878906, 0.8669999837875366, 28.0] => 0 (oczekiwane 1)\n",
      "[5.0, 139.0, 64.0, 35.0, 140.0, 28.600000381469727, 0.41100001335144043, 26.0] => 1 (oczekiwane 0)\n",
      "[5.0, 137.0, 108.0, 0.0, 0.0, 48.79999923706055, 0.22699999809265137, 37.0] => 0 (oczekiwane 1)\n",
      "[13.0, 106.0, 72.0, 54.0, 0.0, 36.599998474121094, 0.17800000309944153, 45.0] => 1 (oczekiwane 0)\n",
      "[4.0, 134.0, 72.0, 0.0, 0.0, 23.799999237060547, 0.2770000100135803, 60.0] => 0 (oczekiwane 1)\n",
      "[6.0, 144.0, 72.0, 27.0, 228.0, 33.900001525878906, 0.2549999952316284, 40.0] => 1 (oczekiwane 0)\n",
      "[1.0, 122.0, 90.0, 51.0, 220.0, 49.70000076293945, 0.32499998807907104, 31.0] => 0 (oczekiwane 1)\n",
      "[1.0, 151.0, 60.0, 0.0, 0.0, 26.100000381469727, 0.17900000512599945, 22.0] => 1 (oczekiwane 0)\n",
      "[4.0, 144.0, 58.0, 28.0, 140.0, 29.5, 0.28700000047683716, 37.0] => 1 (oczekiwane 0)\n",
      "[0.0, 95.0, 85.0, 25.0, 36.0, 37.400001525878906, 0.24699999392032623, 24.0] => 0 (oczekiwane 1)\n",
      "[3.0, 171.0, 72.0, 33.0, 135.0, 33.29999923706055, 0.19900000095367432, 24.0] => 0 (oczekiwane 1)\n",
      "[4.0, 146.0, 92.0, 0.0, 0.0, 31.200000762939453, 0.5389999747276306, 61.0] => 0 (oczekiwane 1)\n",
      "[5.0, 124.0, 74.0, 0.0, 0.0, 34.0, 0.2199999988079071, 38.0] => 0 (oczekiwane 1)\n",
      "[0.0, 162.0, 76.0, 56.0, 100.0, 53.20000076293945, 0.7590000033378601, 25.0] => 0 (oczekiwane 1)\n",
      "[0.0, 113.0, 76.0, 0.0, 0.0, 33.29999923706055, 0.27799999713897705, 23.0] => 0 (oczekiwane 1)\n",
      "[1.0, 88.0, 30.0, 42.0, 99.0, 55.0, 0.4959999918937683, 26.0] => 0 (oczekiwane 1)\n",
      "[1.0, 117.0, 88.0, 24.0, 145.0, 34.5, 0.40299999713897705, 40.0] => 0 (oczekiwane 1)\n",
      "[0.0, 105.0, 84.0, 0.0, 0.0, 27.899999618530273, 0.7409999966621399, 62.0] => 0 (oczekiwane 1)\n",
      "[10.0, 108.0, 66.0, 0.0, 0.0, 32.400001525878906, 0.2720000147819519, 42.0] => 0 (oczekiwane 1)\n",
      "[4.0, 154.0, 62.0, 31.0, 284.0, 32.79999923706055, 0.2370000034570694, 23.0] => 1 (oczekiwane 0)\n",
      "[0.0, 131.0, 88.0, 0.0, 0.0, 31.600000381469727, 0.7429999709129333, 32.0] => 0 (oczekiwane 1)\n",
      "[6.0, 104.0, 74.0, 18.0, 156.0, 29.899999618530273, 0.722000002861023, 41.0] => 0 (oczekiwane 1)\n",
      "[3.0, 148.0, 66.0, 25.0, 0.0, 32.5, 0.25600001215934753, 22.0] => 1 (oczekiwane 0)\n",
      "[6.0, 102.0, 82.0, 0.0, 0.0, 30.799999237060547, 0.18000000715255737, 36.0] => 0 (oczekiwane 1)\n",
      "[6.0, 134.0, 70.0, 23.0, 130.0, 35.400001525878906, 0.5419999957084656, 29.0] => 0 (oczekiwane 1)\n",
      "[0.0, 129.0, 110.0, 46.0, 130.0, 67.0999984741211, 0.3190000057220459, 26.0] => 0 (oczekiwane 1)\n",
      "[5.0, 143.0, 78.0, 0.0, 0.0, 45.0, 0.1899999976158142, 47.0] => 1 (oczekiwane 0)\n",
      "[1.0, 128.0, 98.0, 41.0, 58.0, 32.0, 1.3209999799728394, 33.0] => 0 (oczekiwane 1)\n",
      "[8.0, 109.0, 76.0, 39.0, 114.0, 27.899999618530273, 0.6399999856948853, 31.0] => 0 (oczekiwane 1)\n",
      "[5.0, 139.0, 80.0, 35.0, 160.0, 31.600000381469727, 0.3610000014305115, 25.0] => 0 (oczekiwane 1)\n",
      "[3.0, 107.0, 62.0, 13.0, 48.0, 22.899999618530273, 0.6779999732971191, 23.0] => 0 (oczekiwane 1)\n",
      "[4.0, 109.0, 64.0, 44.0, 99.0, 34.79999923706055, 0.9049999713897705, 26.0] => 0 (oczekiwane 1)\n",
      "[7.0, 179.0, 95.0, 31.0, 0.0, 34.20000076293945, 0.164000004529953, 60.0] => 1 (oczekiwane 0)\n",
      "[0.0, 140.0, 65.0, 26.0, 130.0, 42.599998474121094, 0.4309999942779541, 24.0] => 0 (oczekiwane 1)\n",
      "[9.0, 112.0, 82.0, 32.0, 175.0, 34.20000076293945, 0.25999999046325684, 36.0] => 0 (oczekiwane 1)\n",
      "[5.0, 109.0, 62.0, 41.0, 129.0, 35.79999923706055, 0.5139999985694885, 25.0] => 0 (oczekiwane 1)\n",
      "[5.0, 85.0, 74.0, 22.0, 0.0, 29.0, 1.2239999771118164, 32.0] => 0 (oczekiwane 1)\n",
      "[5.0, 112.0, 66.0, 0.0, 0.0, 37.79999923706055, 0.26100000739097595, 41.0] => 0 (oczekiwane 1)\n",
      "[2.0, 158.0, 90.0, 0.0, 0.0, 31.600000381469727, 0.8050000071525574, 66.0] => 0 (oczekiwane 1)\n",
      "[7.0, 142.0, 60.0, 33.0, 190.0, 28.799999237060547, 0.6869999766349792, 61.0] => 1 (oczekiwane 0)\n",
      "[4.0, 197.0, 70.0, 39.0, 744.0, 36.70000076293945, 2.3289999961853027, 31.0] => 1 (oczekiwane 0)\n",
      "[4.0, 142.0, 86.0, 0.0, 0.0, 44.0, 0.6449999809265137, 22.0] => 0 (oczekiwane 1)\n",
      "[4.0, 122.0, 68.0, 0.0, 0.0, 35.0, 0.39399999380111694, 29.0] => 1 (oczekiwane 0)\n",
      "[0.0, 179.0, 90.0, 27.0, 0.0, 44.099998474121094, 0.6859999895095825, 23.0] => 0 (oczekiwane 1)\n",
      "[10.0, 122.0, 68.0, 0.0, 0.0, 31.200000762939453, 0.257999986410141, 41.0] => 1 (oczekiwane 0)\n",
      "[9.0, 124.0, 70.0, 33.0, 402.0, 35.400001525878906, 0.28200000524520874, 34.0] => 1 (oczekiwane 0)\n",
      "[12.0, 92.0, 62.0, 7.0, 258.0, 27.600000381469727, 0.9259999990463257, 44.0] => 0 (oczekiwane 1)\n",
      "[1.0, 113.0, 64.0, 35.0, 0.0, 33.599998474121094, 0.5429999828338623, 21.0] => 0 (oczekiwane 1)\n",
      "[1.0, 193.0, 50.0, 16.0, 375.0, 25.899999618530273, 0.6549999713897705, 24.0] => 1 (oczekiwane 0)\n",
      "[3.0, 191.0, 68.0, 15.0, 130.0, 30.899999618530273, 0.29899999499320984, 34.0] => 1 (oczekiwane 0)\n",
      "[4.0, 123.0, 62.0, 0.0, 0.0, 32.0, 0.22599999606609344, 35.0] => 0 (oczekiwane 1)\n",
      "[10.0, 101.0, 86.0, 37.0, 0.0, 45.599998474121094, 1.1360000371932983, 38.0] => 0 (oczekiwane 1)\n",
      "[7.0, 106.0, 60.0, 24.0, 0.0, 26.5, 0.29600000381469727, 29.0] => 0 (oczekiwane 1)\n",
      "[2.0, 108.0, 80.0, 0.0, 0.0, 27.0, 0.2590000033378601, 52.0] => 0 (oczekiwane 1)\n",
      "[7.0, 136.0, 74.0, 26.0, 135.0, 26.0, 0.6470000147819519, 51.0] => 1 (oczekiwane 0)\n",
      "[5.0, 155.0, 84.0, 44.0, 545.0, 38.70000076293945, 0.6190000176429749, 34.0] => 1 (oczekiwane 0)\n",
      "[1.0, 119.0, 86.0, 39.0, 220.0, 45.599998474121094, 0.8080000281333923, 29.0] => 0 (oczekiwane 1)\n",
      "[0.0, 107.0, 62.0, 30.0, 74.0, 36.599998474121094, 0.7570000290870667, 25.0] => 0 (oczekiwane 1)\n",
      "[2.0, 128.0, 78.0, 37.0, 182.0, 43.29999923706055, 1.2239999771118164, 31.0] => 0 (oczekiwane 1)\n",
      "[6.0, 151.0, 62.0, 31.0, 120.0, 35.5, 0.6919999718666077, 28.0] => 1 (oczekiwane 0)\n",
      "[2.0, 144.0, 58.0, 33.0, 135.0, 31.600000381469727, 0.421999990940094, 25.0] => 0 (oczekiwane 1)\n",
      "[5.0, 115.0, 98.0, 0.0, 0.0, 52.900001525878906, 0.20900000631809235, 28.0] => 0 (oczekiwane 1)\n",
      "[0.0, 128.0, 68.0, 19.0, 180.0, 30.5, 1.3910000324249268, 25.0] => 0 (oczekiwane 1)\n",
      "[2.0, 124.0, 68.0, 28.0, 205.0, 32.900001525878906, 0.875, 30.0] => 0 (oczekiwane 1)\n",
      "[2.0, 155.0, 74.0, 17.0, 96.0, 26.600000381469727, 0.43299999833106995, 27.0] => 0 (oczekiwane 1)\n",
      "[7.0, 109.0, 80.0, 31.0, 0.0, 35.900001525878906, 1.1269999742507935, 43.0] => 0 (oczekiwane 1)\n",
      "[3.0, 112.0, 74.0, 30.0, 0.0, 31.600000381469727, 0.19699999690055847, 25.0] => 0 (oczekiwane 1)\n",
      "[0.0, 124.0, 70.0, 20.0, 0.0, 27.399999618530273, 0.2540000081062317, 36.0] => 0 (oczekiwane 1)\n",
      "[13.0, 152.0, 90.0, 33.0, 29.0, 26.799999237060547, 0.7310000061988831, 43.0] => 0 (oczekiwane 1)\n",
      "[1.0, 122.0, 64.0, 32.0, 156.0, 35.099998474121094, 0.6919999718666077, 30.0] => 0 (oczekiwane 1)\n",
      "[10.0, 179.0, 70.0, 0.0, 0.0, 35.099998474121094, 0.20000000298023224, 37.0] => 1 (oczekiwane 0)\n",
      "[2.0, 102.0, 86.0, 36.0, 120.0, 45.5, 0.12700000405311584, 23.0] => 0 (oczekiwane 1)\n",
      "[0.0, 165.0, 76.0, 43.0, 255.0, 47.900001525878906, 0.2590000033378601, 26.0] => 1 (oczekiwane 0)\n",
      "[5.0, 115.0, 76.0, 0.0, 0.0, 31.200000762939453, 0.34299999475479126, 44.0] => 0 (oczekiwane 1)\n",
      "[3.0, 116.0, 0.0, 0.0, 0.0, 23.5, 0.18700000643730164, 23.0] => 1 (oczekiwane 0)\n",
      "[4.0, 146.0, 78.0, 0.0, 0.0, 38.5, 0.5199999809265137, 67.0] => 0 (oczekiwane 1)\n",
      "[4.0, 147.0, 74.0, 25.0, 293.0, 34.900001525878906, 0.38499999046325684, 30.0] => 1 (oczekiwane 0)\n",
      "[6.0, 124.0, 72.0, 0.0, 0.0, 27.600000381469727, 0.36800000071525574, 29.0] => 0 (oczekiwane 1)\n",
      "[1.0, 133.0, 102.0, 28.0, 140.0, 32.79999923706055, 0.23399999737739563, 45.0] => 0 (oczekiwane 1)\n",
      "[2.0, 122.0, 52.0, 43.0, 158.0, 36.20000076293945, 0.8159999847412109, 28.0] => 1 (oczekiwane 0)\n",
      "[5.0, 116.0, 74.0, 29.0, 0.0, 32.29999923706055, 0.6600000262260437, 35.0] => 0 (oczekiwane 1)\n",
      "[8.0, 105.0, 100.0, 36.0, 0.0, 43.29999923706055, 0.23899999260902405, 45.0] => 0 (oczekiwane 1)\n",
      "[0.0, 131.0, 66.0, 40.0, 0.0, 34.29999923706055, 0.19599999487400055, 22.0] => 0 (oczekiwane 1)\n",
      "[4.0, 95.0, 64.0, 0.0, 0.0, 32.0, 0.16099999845027924, 31.0] => 0 (oczekiwane 1)\n",
      "[5.0, 136.0, 84.0, 41.0, 88.0, 35.0, 0.28600001335144043, 35.0] => 0 (oczekiwane 1)\n",
      "[2.0, 123.0, 48.0, 32.0, 165.0, 42.099998474121094, 0.5199999809265137, 26.0] => 1 (oczekiwane 0)\n",
      "[4.0, 115.0, 72.0, 0.0, 0.0, 28.899999618530273, 0.37599998712539673, 46.0] => 0 (oczekiwane 1)\n",
      "[0.0, 138.0, 60.0, 35.0, 167.0, 34.599998474121094, 0.5339999794960022, 21.0] => 0 (oczekiwane 1)\n",
      "[3.0, 173.0, 84.0, 33.0, 474.0, 35.70000076293945, 0.257999986410141, 22.0] => 0 (oczekiwane 1)\n",
      "[4.0, 144.0, 82.0, 32.0, 0.0, 38.5, 0.5540000200271606, 37.0] => 0 (oczekiwane 1)\n",
      "[3.0, 129.0, 64.0, 29.0, 115.0, 26.399999618530273, 0.21899999678134918, 28.0] => 0 (oczekiwane 1)\n",
      "[1.0, 95.0, 82.0, 25.0, 180.0, 35.0, 0.2329999953508377, 43.0] => 0 (oczekiwane 1)\n",
      "[12.0, 140.0, 85.0, 33.0, 0.0, 37.400001525878906, 0.24400000274181366, 41.0] => 1 (oczekiwane 0)\n",
      "[5.0, 147.0, 75.0, 0.0, 0.0, 29.899999618530273, 0.4339999854564667, 28.0] => 1 (oczekiwane 0)\n",
      "[0.0, 189.0, 104.0, 25.0, 0.0, 34.29999923706055, 0.4350000023841858, 41.0] => 0 (oczekiwane 1)\n",
      "[8.0, 108.0, 70.0, 0.0, 0.0, 30.5, 0.9549999833106995, 33.0] => 0 (oczekiwane 1)\n",
      "[4.0, 117.0, 62.0, 12.0, 0.0, 29.700000762939453, 0.3799999952316284, 30.0] => 0 (oczekiwane 1)\n",
      "[0.0, 104.0, 64.0, 37.0, 64.0, 33.599998474121094, 0.5099999904632568, 22.0] => 0 (oczekiwane 1)\n",
      "[2.0, 134.0, 70.0, 0.0, 0.0, 28.899999618530273, 0.5419999957084656, 23.0] => 0 (oczekiwane 1)\n",
      "[6.0, 154.0, 78.0, 41.0, 140.0, 46.099998474121094, 0.5709999799728394, 27.0] => 1 (oczekiwane 0)\n",
      "[2.0, 105.0, 80.0, 45.0, 191.0, 33.70000076293945, 0.7110000252723694, 29.0] => 0 (oczekiwane 1)\n",
      "[0.0, 135.0, 68.0, 42.0, 250.0, 42.29999923706055, 0.36500000953674316, 24.0] => 0 (oczekiwane 1)\n",
      "[0.0, 173.0, 78.0, 32.0, 265.0, 46.5, 1.159000039100647, 58.0] => 1 (oczekiwane 0)\n",
      "[8.0, 194.0, 80.0, 0.0, 0.0, 26.100000381469727, 0.5509999990463257, 67.0] => 1 (oczekiwane 0)\n",
      "[4.0, 125.0, 70.0, 18.0, 122.0, 28.899999618530273, 1.1440000534057617, 45.0] => 0 (oczekiwane 1)\n",
      "[6.0, 154.0, 74.0, 32.0, 193.0, 29.299999237060547, 0.8389999866485596, 39.0] => 1 (oczekiwane 0)\n",
      "[0.0, 180.0, 90.0, 26.0, 90.0, 36.5, 0.3140000104904175, 35.0] => 0 (oczekiwane 1)\n",
      "[12.0, 84.0, 72.0, 31.0, 0.0, 29.700000762939453, 0.296999990940094, 46.0] => 0 (oczekiwane 1)\n",
      "[3.0, 163.0, 70.0, 18.0, 105.0, 31.600000381469727, 0.2680000066757202, 28.0] => 0 (oczekiwane 1)\n",
      "[3.0, 125.0, 58.0, 0.0, 0.0, 31.600000381469727, 0.1509999930858612, 24.0] => 1 (oczekiwane 0)\n",
      "[3.0, 129.0, 92.0, 49.0, 155.0, 36.400001525878906, 0.9679999947547913, 32.0] => 0 (oczekiwane 1)\n",
      "[3.0, 128.0, 72.0, 25.0, 190.0, 32.400001525878906, 0.5490000247955322, 27.0] => 0 (oczekiwane 1)\n",
      "[10.0, 90.0, 85.0, 32.0, 0.0, 34.900001525878906, 0.824999988079071, 56.0] => 0 (oczekiwane 1)\n",
      "[7.0, 124.0, 70.0, 33.0, 215.0, 25.5, 0.16099999845027924, 37.0] => 1 (oczekiwane 0)\n",
      "[11.0, 103.0, 68.0, 40.0, 0.0, 46.20000076293945, 0.12600000202655792, 42.0] => 1 (oczekiwane 0)\n",
      "[6.0, 125.0, 76.0, 0.0, 0.0, 33.79999923706055, 0.12099999934434891, 54.0] => 0 (oczekiwane 1)\n",
      "[0.0, 121.0, 66.0, 30.0, 165.0, 34.29999923706055, 0.2029999941587448, 33.0] => 0 (oczekiwane 1)\n",
      "[6.0, 108.0, 44.0, 20.0, 130.0, 24.0, 0.8130000233650208, 35.0] => 1 (oczekiwane 0)\n",
      "[2.0, 118.0, 80.0, 0.0, 0.0, 42.900001525878906, 0.6930000185966492, 21.0] => 0 (oczekiwane 1)\n",
      "[10.0, 133.0, 68.0, 0.0, 0.0, 27.0, 0.24500000476837158, 36.0] => 1 (oczekiwane 0)\n",
      "[0.0, 151.0, 90.0, 46.0, 0.0, 42.099998474121094, 0.3709999918937683, 21.0] => 0 (oczekiwane 1)\n",
      "[3.0, 132.0, 80.0, 0.0, 0.0, 34.400001525878906, 0.4020000100135803, 44.0] => 0 (oczekiwane 1)\n",
      "[6.0, 123.0, 72.0, 45.0, 230.0, 33.599998474121094, 0.7329999804496765, 34.0] => 1 (oczekiwane 0)\n",
      "[0.0, 188.0, 82.0, 14.0, 185.0, 32.0, 0.6819999814033508, 22.0] => 0 (oczekiwane 1)\n",
      "[9.0, 112.0, 82.0, 24.0, 0.0, 28.200000762939453, 1.281999945640564, 50.0] => 0 (oczekiwane 1)\n",
      "[6.0, 183.0, 94.0, 0.0, 0.0, 40.79999923706055, 1.4609999656677246, 45.0] => 1 (oczekiwane 0)\n",
      "[7.0, 114.0, 64.0, 0.0, 0.0, 27.399999618530273, 0.7319999933242798, 34.0] => 0 (oczekiwane 1)\n",
      "[13.0, 104.0, 72.0, 0.0, 0.0, 31.200000762939453, 0.4650000035762787, 38.0] => 0 (oczekiwane 1)\n",
      "[7.0, 97.0, 76.0, 32.0, 91.0, 40.900001525878906, 0.8709999918937683, 32.0] => 0 (oczekiwane 1)\n",
      "[6.0, 147.0, 80.0, 0.0, 0.0, 29.5, 0.17800000309944153, 50.0] => 0 (oczekiwane 1)\n",
      "[2.0, 157.0, 74.0, 35.0, 440.0, 39.400001525878906, 0.1340000033378601, 30.0] => 1 (oczekiwane 0)\n",
      "[1.0, 167.0, 74.0, 17.0, 144.0, 23.399999618530273, 0.44699999690055847, 33.0] => 0 (oczekiwane 1)\n",
      "[11.0, 136.0, 84.0, 35.0, 130.0, 28.299999237060547, 0.25999999046325684, 42.0] => 0 (oczekiwane 1)\n",
      "[3.0, 80.0, 82.0, 31.0, 70.0, 34.20000076293945, 1.2920000553131104, 27.0] => 0 (oczekiwane 1)\n",
      "[10.0, 162.0, 84.0, 0.0, 0.0, 27.700000762939453, 0.18199999630451202, 54.0] => 1 (oczekiwane 0)\n",
      "[4.0, 145.0, 82.0, 18.0, 0.0, 32.5, 0.23499999940395355, 70.0] => 0 (oczekiwane 1)\n",
      "[6.0, 98.0, 58.0, 33.0, 190.0, 34.0, 0.4300000071525574, 43.0] => 1 (oczekiwane 0)\n",
      "[6.0, 165.0, 68.0, 26.0, 168.0, 33.599998474121094, 0.6309999823570251, 49.0] => 1 (oczekiwane 0)\n",
      "[4.0, 125.0, 80.0, 0.0, 0.0, 32.29999923706055, 0.5360000133514404, 27.0] => 0 (oczekiwane 1)\n",
      "[1.0, 144.0, 82.0, 46.0, 180.0, 46.099998474121094, 0.33500000834465027, 46.0] => 0 (oczekiwane 1)\n",
      "[7.0, 142.0, 90.0, 24.0, 480.0, 30.399999618530273, 0.12800000607967377, 43.0] => 0 (oczekiwane 1)\n",
      "[3.0, 169.0, 74.0, 19.0, 125.0, 29.899999618530273, 0.2680000066757202, 31.0] => 0 (oczekiwane 1)\n",
      "[4.0, 118.0, 70.0, 0.0, 0.0, 44.5, 0.9039999842643738, 26.0] => 1 (oczekiwane 0)\n",
      "[6.0, 125.0, 78.0, 31.0, 0.0, 27.600000381469727, 0.5649999976158142, 49.0] => 0 (oczekiwane 1)\n",
      "[2.0, 129.0, 0.0, 0.0, 0.0, 38.5, 0.30399999022483826, 41.0] => 1 (oczekiwane 0)\n",
      "[10.0, 115.0, 0.0, 0.0, 0.0, 0.0, 0.26100000739097595, 30.0] => 0 (oczekiwane 1)\n",
      "[2.0, 93.0, 64.0, 32.0, 160.0, 38.0, 0.6740000247955322, 23.0] => 0 (oczekiwane 1)\n",
      "[5.0, 97.0, 76.0, 27.0, 0.0, 35.599998474121094, 0.3779999911785126, 52.0] => 0 (oczekiwane 1)\n",
      "[1.0, 149.0, 68.0, 29.0, 127.0, 29.299999237060547, 0.3490000069141388, 42.0] => 0 (oczekiwane 1)\n",
      "[3.0, 130.0, 78.0, 23.0, 79.0, 28.399999618530273, 0.3230000138282776, 34.0] => 0 (oczekiwane 1)\n",
      "[8.0, 120.0, 86.0, 0.0, 0.0, 28.399999618530273, 0.2590000033378601, 22.0] => 0 (oczekiwane 1)\n",
      "[2.0, 174.0, 88.0, 37.0, 120.0, 44.5, 0.6460000276565552, 24.0] => 0 (oczekiwane 1)\n",
      "[1.0, 102.0, 74.0, 0.0, 0.0, 39.5, 0.2930000126361847, 42.0] => 0 (oczekiwane 1)\n",
      "[9.0, 140.0, 94.0, 0.0, 0.0, 32.70000076293945, 0.734000027179718, 45.0] => 0 (oczekiwane 1)\n",
      "[13.0, 153.0, 88.0, 37.0, 140.0, 40.599998474121094, 1.1740000247955322, 39.0] => 1 (oczekiwane 0)\n",
      "[1.0, 147.0, 94.0, 41.0, 0.0, 49.29999923706055, 0.3580000102519989, 27.0] => 0 (oczekiwane 1)\n",
      "[0.0, 181.0, 88.0, 44.0, 510.0, 43.29999923706055, 0.22200000286102295, 26.0] => 0 (oczekiwane 1)\n",
      "[1.0, 128.0, 88.0, 39.0, 110.0, 36.5, 1.0570000410079956, 37.0] => 0 (oczekiwane 1)\n",
      "[0.0, 123.0, 72.0, 0.0, 0.0, 36.29999923706055, 0.257999986410141, 52.0] => 0 (oczekiwane 1)\n",
      "[10.0, 101.0, 76.0, 48.0, 180.0, 32.900001525878906, 0.17100000381469727, 63.0] => 1 (oczekiwane 0)\n",
      "[1.0, 126.0, 60.0, 0.0, 0.0, 30.100000381469727, 0.3490000069141388, 47.0] => 0 (oczekiwane 1)\n"
     ]
    }
   ],
   "source": [
    "predictions = (model(X) > 0.5).int()\n",
    "for i in range(len(y)):\n",
    "    if y[i] != predictions[i]:\n",
    "        print('%s => %d (oczekiwane %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.892      0.108     ]\n",
      " [0.48134328 0.51865672]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "conf = confusion_matrix(y,predictions,normalize='true')\n",
    "print(conf)\n",
    "sns.heatmap(conf,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
